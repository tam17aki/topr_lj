TOPR: # TOPR: Two-stage Online Phase Reconstruction
  root_dir: "/work/tamamori/topr_lj/"
  data_dir: "data/"
  trainset_dir: "train/"
  devset_dir: "dev/"
  evalset_dir: "eval/"
  list_dir: "list/"
  split_dir: "split/"
  label_dir: "label/"
  feat_dir: "feat/"
  model_dir: "model/"
  demo_dir: "demo/"
  score_dir: "score/"
  fig_dir: "fig/"
  ltfat_dir: "/work/tamamori/ltfat-main"

preprocess:
  n_dev: 300
  n_eval: 300
  n_jobs: 6
  sec_per_split: 1.0  # in seconds (DO NOT EDIT!)

feature:
  sample_rate: 22050  # sampling frequency
  win_length: 1024     # analysis window length (frame length)
  hop_length: 256     # hop length (frame shift length)
  window: "hann"      # window type
  n_fft: 1024          # FFT length

model:
  n_lookahead: 0 # number of look-ahead frames; if positive, model will be offline.
  n_lookback: 3  # number of look-back frames; must be positive.
  kernel_size: 5 # for 1 FreqGatedConv & 2 residual connections
  n_channels: 64 # number of conv channels except the first and last FreqConv

training:
  n_epoch: 30
  n_batch: 32
  num_workers: 1
  model_file: "model"
  report_interval: 1
  optim:
    optimizer:
      name: RAdam
      params:  # add items according to optimizer
        lr: 0.001  # learning rate
        weight_decay: 0.000001
        decoupled_weight_decay: False # True: enable AdamW style
    lr_scheduler:
      name: CosineAnnealingWithWarmupLR
      cosine_params:
        warmup_epochs: 5
        max_epochs: 30
        warmup_start_lr: 0.000001
        eta_min: 0.0005
  use_scheduler: True  # True: enable scheduler
  use_grad_clip: True  # True enable gradient clipping
  grad_max_norm: 10  # clipping value

demo:
  stoi_extended: True  # True: extended STOI
  weighted_rpu: False  # True: weighted RPU
  weight_power_rpu: 5.0  # power of weight
  weight_power: 1.0  # power of weight
  weight_gamma: 100.0  # scaler to weight
